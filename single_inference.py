import cvzone
from ultralytics import YOLO
import cv2
import numpy as np
import torch
import pickle
import os
import sys
from torchvision import transforms
from PIL import Image

# --- IMPORTURI CUSTOM ---
from model import MobileFaceNet
from Yolo import run_face_inference_test  # Varianta complexÄƒ pentru test

# ==========================================
# 0. CONFIGURÄ‚RI
# ==========================================
# Calea specificÄƒ cÄƒtre imaginea ta
TEST_IMAGE_PATH = r'C:\Users\raduc\Downloads\dataset\dataset\test\Outdoor\Masked\Pablo - Outdoor - M12C.png'
#TEST_IMAGE_PATH = r'C:\Users\raduc\Downloads\dataset\dataset\test\Outdoor\Non-masked\Pablo - Outdoor - 6C.png'
# FiÈ™ierele necesare
DB_FILE = 'face_db.pkl'
WEIGHTS_PATH = 'model_mobilefacenet.pth'

# Configurare detecÈ›ie
THRESHOLD = 0.13 # Pragul de siguranÈ›Äƒ (40%)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print(f"âš™ï¸  System ready using: {device}")

# ==========================================
# 1. PREGÄ‚TIRE (HELPER FUNCTIONS)
# ==========================================

# Preprocesare identicÄƒ cu cea de la antrenare
preprocess = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((112, 112)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])


def get_embedding(full_image_bgr, coords, model):
    """ Extrage vectorul dintr-o faÈ›Äƒ decupatÄƒ """
    x1, y1, x2, y2 = coords
    h, w = full_image_bgr.shape[:2]

    # Safe Crop (sÄƒ nu ieÈ™im din pozÄƒ)
    x1, y1 = max(0, x1), max(0, y1)
    x2, y2 = min(w, x2), min(h, y2)

    # DacÄƒ faÈ›a e prea micÄƒ, o ignorÄƒm
    if x2 - x1 < 10 or y2 - y1 < 10: return None

    # Decupare din imaginea mare
    face_crop = full_image_bgr[y1:y2, x1:x2]

    # !!! CRITIC: Conversie BGR -> RGB !!!
    # OpenCV citeÈ™te BGR, MobileFaceNet vrea RGB
    face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)

    # Transformare Ã®n Tensor È™i mutare pe GPU
    input_tensor = preprocess(face_rgb).unsqueeze(0).to(device)

    with torch.no_grad():
        embedding = model(input_tensor)
        embedding = embedding.cpu().numpy()[0]

    return embedding


# ==========================================
# 2. ÃNCÄ‚RCARE RESURSE
# ==========================================

# A. Baza de date
if not os.path.exists(DB_FILE):
    print(f"âŒ EROARE: Nu gÄƒsesc '{DB_FILE}'. RuleazÄƒ create_db.py!")
    sys.exit()

print("ğŸ“‚ Ãncarc baza de date...")
with open(DB_FILE, 'rb') as f:
    face_db = pickle.load(f)
print(f"âœ… BazÄƒ de date Ã®ncÄƒrcatÄƒ. ConÈ›ine {len(face_db)} persoane.")

# B. Modele YOLO
print("â³ Ãncarc YOLO...")
try:
    person_model = YOLO('yolo11n.pt')  # DetecteazÄƒ oameni
    face_model = YOLO('yolov12m-face.pt')  # DetecteazÄƒ feÈ›e
except Exception as e:
    print(f"âŒ Eroare YOLO: {e}")
    sys.exit()

# C. MobileFaceNet
print("â³ Ãncarc MobileFaceNet...")
embed_model = MobileFaceNet(512).to(device)
try:
    checkpoint = torch.load(WEIGHTS_PATH, map_location=device)
    if 'state_dict' in checkpoint:
        embed_model.load_state_dict(checkpoint['state_dict'])
    else:
        embed_model.load_state_dict(checkpoint)
    embed_model.eval()
except Exception as e:
    print(f"âŒ Eroare MobileFaceNet: {e}")
    sys.exit()

# ==========================================
# 3. EXECUÈšIE PE IMAGINEA TA
# ==========================================

print(f"\nğŸ–¼ï¸  Procesez imaginea: {os.path.basename(TEST_IMAGE_PATH)}")

# 1. Citire Imagine
frame = cv2.imread(TEST_IMAGE_PATH)
if frame is None:
    print("âŒ Nu am putut citi imaginea! VerificÄƒ calea.")
    sys.exit()

# 2. DetecÈ›ie ComplexÄƒ (Person -> Upscale -> Face)
detections = run_face_inference_test(person_model, face_model, frame)

if len(detections) == 0:
    print("âš ï¸  Nu am detectat nicio faÈ›Äƒ Ã®n imagine.")
    # AfiÈ™Äƒm imaginea originalÄƒ oricum
    cv2.imshow("Rezultat", frame)
    cv2.waitKey(0)
    sys.exit()

print(f"âœ… Am detectat {len(detections)} faÈ›Äƒ/feÈ›e. Ãncep recunoaÈ™terea...")

# 3. RecunoaÈ™tere pentru fiecare faÈ›Äƒ
for i, det in enumerate(detections):
    box = det['face_box']  # [x1, y1, x2, y2]

    # GenerÄƒm amprenta feÈ›ei curente (Embedding)
    current_vector = get_embedding(frame, box, embed_model)

    if current_vector is None: continue

    # NormalizÄƒm vectorul curent (EsenÈ›ial pentru acurateÈ›e)
    current_vector = current_vector / np.linalg.norm(current_vector)

    # --- COMPARARE CU CEI 10 OAMENI DIN BAZÄ‚ ---
    best_name = "Unknown"
    max_similarity = -1.0

    print(f"\n--- AnalizÄƒ FaÈ›a #{i + 1} ---")

    for db_name, db_vector in face_db.items():
        # CalculÄƒm similaritatea (Produs Scalar)
        score = np.dot(current_vector, db_vector)

        # AfiÈ™Äƒm scorul pentru fiecare persoanÄƒ (pentru debug)
        print(f"   vs {db_name:<10}: {score:.4f}")

        if score > max_similarity:
            max_similarity = score
            best_name = db_name

    # 4. Decizie FinalÄƒ
    if max_similarity >= THRESHOLD:
        print(f"ğŸ† REZULTAT: Este {best_name} (SiguranÈ›Äƒ: {max_similarity:.2f})")
        color = (0, 255, 0)  # Verde
        text = f"{best_name} {max_similarity:.2f}"
    else:
        print(f"âš ï¸ REZULTAT: PersoanÄƒ NecunoscutÄƒ (Cel mai apropiat: {best_name} cu {max_similarity:.2f})")
        color = (0, 0, 255)  # RoÈ™u
        text = f"Unknown ({best_name}?)"

    # 5. Desenare pe imagine
    x1, y1, x2, y2 = box
    w, h = x2 - x1, y2 - y1
    cvzone.cornerRect(frame, [x1, y1, w, h], l=15, rt=1, colorR=color)
    cvzone.putTextRect(frame, text, (max(0, x1), max(20, y1 - 10)), scale=1, thickness=1, colorR=color)

# ==========================================
# 4. AFIÈ˜ARE VIZUALÄ‚
# ==========================================
h, w = frame.shape[:2]
# RedimensionÄƒm doar pentru afiÈ™are dacÄƒ e prea mare
if h > 1000:
    scale = 1000 / h
    dim = (int(w * scale), 1000)
    frame = cv2.resize(frame, dim)

cv2.imshow("TEST PABLO", frame)
print("\nApasa orice tasta pe fereastra imaginii pentru a inchide...")
cv2.waitKey(0)
cv2.destroyAllWindows()